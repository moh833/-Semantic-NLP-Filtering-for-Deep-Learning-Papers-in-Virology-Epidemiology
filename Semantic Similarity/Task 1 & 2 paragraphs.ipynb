{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133a2350-c8df-43a1-803c-f8394e96bc36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93816d0-e4fb-4874-be33-8952690c241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/collection_with_abstracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251dde0f-00d6-40b8-a6b1-318adc86d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Abstract'] = df['Abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7700ef-3d57-45a6-9599-e3bceb57ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_data'] = df.apply(lambda row: row['Title'] + '\\n\\n' + row['Abstract'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ceef6-6189-4dfb-8bcf-a9daef70debc",
   "metadata": {},
   "source": [
    "# Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d501f3-4351-4101-b43a-a3f084625658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_mining_phrases = [\"natural language processing\", \"text mining\", \"NLP\", \"computational linguistics\", \"language processing\", \"text analytics\", \"textual data analysis\", \"text data analysis\", \"text analysis\", \"speech and language technology\", \"language modeling\", \"computational semantics\"]\n",
    "# computer_vision_phrases = [\"computer vision\", \"vision model\", \"image processing\", \"vision algorithms\", \"computer graphics and vision\", \"object recognition\", \"scene understanding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a99be6a-40cb-4a4c-8f75-fff0370814dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Mas2\\Work\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy\n",
    "\n",
    "# sbert_model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "bi_encoder = SentenceTransformer('msmarco-distilbert-base-v4')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def encode_paragraphs(paragraphs):\n",
    "    paragraph_embeddings_list = []\n",
    "\n",
    "    for PMID, paragraph in paragraphs:\n",
    "\n",
    "        paragraph_embeddings = bi_encoder.encode(paragraph, convert_to_tensor=True)\n",
    "\n",
    "        paragraph_embeddings_list.append({\n",
    "            \"PMID\": PMID,\n",
    "            \"paragraph\": paragraph,\n",
    "            \"paragraph_embeddings\": paragraph_embeddings\n",
    "        })\n",
    "\n",
    "    return paragraph_embeddings_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b0d343-b4a6-4dee-9e27-18e58e957955",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = df[['PMID', 'text_data']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8348f8af-5acd-4d40-94fd-2e3856d03510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39435445,\n",
       " 'Editorial: The operationalization of cognitive systems in the comprehension of visual structures\\n\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1109f4e4-42a6-4b05-a146-8ef7e59089f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode paragraphs\n",
    "paragraph_embeddings_list = encode_paragraphs(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b168e425-1cc6-4825-8a10-bb751dcf8272",
   "metadata": {},
   "source": [
    "# Save and Load paragraph_embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc660cf9-a92c-435f-8050-20ab6a5a2aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"embeddings/paragraph_embeddings_list.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(paragraph_embeddings_list, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf2b0124-e18a-4d46-9c71-ed368059781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"embeddings/paragraph_embeddings_list.pkl\", \"rb\") as file:\n",
    "    paragraph_embeddings_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f4cb240-cdf2-4b85-8ff4-b415d8bccb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "query_embedding = bi_encoder.encode('deep learning', convert_to_tensor=True)\n",
    "\n",
    "paragraph_scores = []\n",
    "\n",
    "\n",
    "paragraph_embeddings = paragraph_embeddings_list[0][\"paragraph_embeddings\"]\n",
    "\n",
    "# Calculate similarity between the query and each sentence in the paragraph\n",
    "similarities = util.cos_sim(query_embedding, paragraph_embeddings)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8478e501-adfe-4ddd-af25-0e42f1fad441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def get_paragraph_similarity_with_query(query, paragraph_embeddings_list):\n",
    "\n",
    "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    paragraph_scores = []\n",
    "\n",
    "    for paragraph_data in paragraph_embeddings_list:\n",
    "\n",
    "        paragraph_embeddings = paragraph_data[\"paragraph_embeddings\"]\n",
    "\n",
    "        similarities = util.cos_sim(query_embedding, paragraph_embeddings)[0]\n",
    "\n",
    "        max_similarity = similarities.max().item()\n",
    "\n",
    "\n",
    "        # Append the paragraph and its max similarity score\n",
    "        # paragraph_scores.append((paragraph_data[\"paragraph\"], max_similarity))\n",
    "        # paragraph_scores.append((paragraph_data[\"sentences\"][max_sim_ind], max_similarity))\n",
    "        paragraph_scores.append({'PMID': paragraph_data['PMID'], 'paragraph': paragraph_data[\"paragraph\"], 'similarity_score': max_similarity})\n",
    "        # paragraph_scores.append({'PMID': paragraph_data['PMID'], 'paragraph': paragraph_data[\"paragraph\"], 'max_sentence': paragraph_data[\"sentences\"][max_sim_ind], 'max_sentence_score': max_similarity})\n",
    "\n",
    "    return paragraph_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff34e3a8-882c-4699-8ca6-291f7b1d85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_embeddings = bi_encoder.encode(['deep learning', 'operationalization'], convert_to_tensor=True)\n",
    "\n",
    "\n",
    "paragraph_embeddings = paragraph_embeddings_list[0][\"paragraph_embeddings\"]\n",
    "\n",
    "similarities = util.cos_sim(queries_embeddings, paragraph_embeddings)\n",
    "\n",
    "max_score = similarities.max().item()\n",
    "\n",
    "max_index = np.argmax(similarities.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5514d41b-773e-4f8c-92e1-8afd13083b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(similarities.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "266b6c8e-ae1d-4a89-99ee-4343ed923bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47679921984672546"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5636d75e-935b-4b5a-8192-4a5f2209837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "29698906-0c12-4c37-90fa-20185f1efadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_encoder = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "bi_encoder = SentenceTransformer('msmarco-distilbert-base-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9c86d-73e2-43a9-a6c4-bf29009e9ebf",
   "metadata": {},
   "source": [
    "# Filter out irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67f4e675-ac6c-478d-b666-3b78b5484ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "import numpy as np\n",
    "\n",
    "def get_max_similarity_with_queries(queries, paragraph_embeddings_list):\n",
    "    \n",
    "    queries_embeddings = bi_encoder.encode(queries, convert_to_tensor=True)\n",
    "\n",
    "    paragraph_scores = []\n",
    "\n",
    "    for paragraph_data in paragraph_embeddings_list:\n",
    "\n",
    "        paragraph_embeddings = paragraph_data[\"paragraph_embeddings\"]\n",
    "        \n",
    "        similarities = util.cos_sim(queries_embeddings, paragraph_embeddings)\n",
    "        \n",
    "        max_score = similarities.max().item()\n",
    "        \n",
    "        max_index = np.argmax(similarities.cpu().numpy())\n",
    "                \n",
    "        data = {'PMID': paragraph_data['PMID'], 'paragraph': paragraph_data[\"paragraph\"], 'phrase_with_max_score': queries[max_index], 'max_score': max_score}\n",
    "        paragraph_scores.append(data)\n",
    "        \n",
    "    return paragraph_scores\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a55e52f8-ad0c-4d37-a298-311d0bac0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(queries, threshold):\n",
    "    paragraph_scores = get_max_similarity_with_queries(queries, paragraph_embeddings_list)\n",
    "    paragraph_scores.sort(key=lambda x: x['max_score'], reverse=True)\n",
    "    # paragraph_scores_filtered = [p for p in paragraph_scores if p['max_score'] >= threshold]\n",
    "    # return paragraph_scores_filtered\n",
    "    # return [p['PMID'] for p in paragraph_scores if p['max_score'] >= threshold]\n",
    "    return set([p['PMID'] for p in paragraph_scores if p['max_score'] >= threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e241904a-7cec-4f5b-8264-f70c6f53c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = get_matches(\"virology\", 0.0), get_matches(\"epidemiology\", 0.0), get_matches(\"deep learning\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02a6d453-7f6e-4f65-a982-20f0669fc9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6721"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((a | b) & c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27d18a03-0fc1-4071-bfef-93b10ac73bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined = (get_matches(\"virology\", 0.0) | get_matches(\"epidemiology\", 0.0)) & get_matches(\"deep learning\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7b9404b-92c0-43da-ad2a-fa5959fa6437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6721"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d50314ab-3962-4016-bd05-972c0e6fce16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paragraph_embeddings_list_filtered = [ p for p in paragraph_embeddings_list if p['PMID'] in combined ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "74b3e6b3-fa3c-4427-b13b-b4108adbf196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6721"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraph_embeddings_list_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cacd83-71b2-4cee-b11a-f44723d67f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9c93cd3-5ca2-4a2d-b10c-1a32109fc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['deep learning in virology', 'deep learning in epidemiology']\n",
    "\n",
    "paragraph_scores = get_max_similarity_with_queries(queries, paragraph_embeddings_list)\n",
    "paragraph_scores.sort(key=lambda x: x['max_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8403bb74-71e9-4c9e-b550-ab1c66deaa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6383"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([p['PMID'] for p in paragraph_scores if p['max_score'] >= 0.15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdba329-b426-4931-a640-7fd02ad06782",
   "metadata": {},
   "source": [
    "# Classify papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b053d3e-453f-42d0-89e2-18a5d6f44740",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mining_phrases = [\"natural language processing\", \"text mining\", \"NLP\", \"computational linguistics\", \"language processing\", \"text analytics\", \"textual data analysis\", \"text data analysis\", \"text analysis\", \"speech and language technology\", \"language modeling\", \"computational semantics\"]\n",
    "computer_vision_phrases = [\"computer vision\", \"vision model\", \"image processing\", \"vision algorithms\", \"computer graphics and vision\", \"object recognition\", \"scene understanding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f4d59c8-21f6-425a-a6bf-65120ad6ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "import numpy as np\n",
    "\n",
    "def get_similarity_with_cv_text_queries(computer_vision_phrases, text_mining_phrases, paragraph_list):\n",
    "    \n",
    "    computer_vision_embeddings = bi_encoder.encode(computer_vision_phrases, convert_to_tensor=True)\n",
    "    text_mining_embeddings = bi_encoder.encode(text_mining_phrases, convert_to_tensor=True)\n",
    "\n",
    "    paragraph_scores = []\n",
    "\n",
    "    for paragraph_data in paragraph_list:\n",
    "\n",
    "        paragraph_embeddings = paragraph_data[\"paragraph_embeddings\"]\n",
    "        \n",
    "        cv_similarities = util.cos_sim(computer_vision_embeddings, paragraph_embeddings)\n",
    "        text_similarities = util.cos_sim(text_mining_embeddings, paragraph_embeddings)\n",
    "        \n",
    "        cv_max_score = util.cos_sim(computer_vision_embeddings, paragraph_embeddings).max().item()\n",
    "        text_max_score = util.cos_sim(text_mining_embeddings, paragraph_embeddings).max().item()\n",
    "        \n",
    "        max_index_1 = np.argmax(cv_similarities.cpu().numpy())\n",
    "        max_index_2 = np.argmax(text_similarities.cpu().numpy())\n",
    "        \n",
    "        computer_vision_max_phrase = computer_vision_phrases[max_index_1]\n",
    "        text_mining_max_phrase = text_mining_phrases[max_index_2]        \n",
    "\n",
    "        \n",
    "        data = {'PMID': paragraph_data['PMID'], 'paragraph': paragraph_data['paragraph'], 'computer_vision_max_phrase': computer_vision_max_phrase, 'computer_vision_max_score': cv_max_score, 'text_mining_max_phrase': text_mining_max_phrase, 'text_mining_max_score': text_max_score}\n",
    "        paragraph_scores.append(data)\n",
    "        \n",
    "    return paragraph_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "10f5e39e-84e3-47d1-93d8-890d874c20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_scores_cv_text = get_similarity_with_cv_text_queries(computer_vision_phrases, text_mining_phrases, paragraph_embeddings_list_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ff0e5984-c447-4571-a5b8-830783cd5ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6721"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraph_scores_cv_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d53b3536-4103-4a57-817d-16469ea28abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_paragraphs(paragraph_scores_cv_text, threshold=0.3):\n",
    "    for data in paragraph_scores_cv_text:\n",
    "        label = ''\n",
    "        if data['computer_vision_max_score'] >= threshold and data['text_mining_max_score'] >= threshold:\n",
    "            label = 'both'\n",
    "        elif data['computer_vision_max_score'] >= threshold:\n",
    "            label = 'computer vision'\n",
    "        elif data['text_mining_max_score'] >= threshold:\n",
    "            label = 'text mining'\n",
    "        else:\n",
    "            label = 'other'\n",
    "        data['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "220d2288-456b-4839-b0ff-f20fa00d9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_paragraphs(paragraph_scores_cv_text, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f425075d-f576-4ac5-984e-ba66eb02e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ d['label'] for d in paragraph_scores_cv_text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a4b7a65a-2e07-40f6-b811-98500cea3420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'both': 2956,\n",
       "         'text mining': 1654,\n",
       "         'other': 1590,\n",
       "         'computer vision': 521})"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d17c84-edb0-4ea6-81b6-b99c6aae0acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda8385-7eb9-431d-a0e3-a1caa38b14cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ef9e8-7187-4710-a64a-5353b6c67857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
